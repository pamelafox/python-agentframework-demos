"""Workflow Escritor → Revisor usando agentes de IA como ejecutores.

Demuestra: Agent como ejecutor de WorkflowBuilder, aristas directas
y recopilación de salida con workflow.run() + get_outputs().

Este ejemplo usa el mismo patrón WorkflowBuilder + add_edge que
workflow_rag_ingest.py, pero con agentes de IA en lugar de funciones Python.

Ejecutar:
    uv run examples/spanish/workflow_agents.py
    uv run examples/spanish/workflow_agents.py --devui  (abre DevUI en http://localhost:8092)
"""

import asyncio
import logging
import os
import sys

from agent_framework import Agent, WorkflowBuilder
from agent_framework.openai import OpenAIChatClient
from azure.identity.aio import DefaultAzureCredential, get_bearer_token_provider
from dotenv import load_dotenv
from rich.logging import RichHandler

log_handler = RichHandler(show_path=False, rich_tracebacks=True, show_level=False)
logging.basicConfig(level=logging.WARNING, handlers=[log_handler], force=True, format="%(message)s")
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

load_dotenv(override=True)
API_HOST = os.getenv("API_HOST", "github")

# Configura el cliente de chat según el proveedor de API
async_credential = None
if API_HOST == "azure":
    async_credential = DefaultAzureCredential()
    token_provider = get_bearer_token_provider(async_credential, "https://cognitiveservices.azure.com/.default")
    client = OpenAIChatClient(
        base_url=f"{os.environ['AZURE_OPENAI_ENDPOINT']}/openai/v1/",
        api_key=token_provider,
        model_id=os.environ["AZURE_OPENAI_CHAT_DEPLOYMENT"],
    )
elif API_HOST == "github":
    client = OpenAIChatClient(
        base_url="https://models.github.ai/inference",
        api_key=os.environ["GITHUB_TOKEN"],
        model_id=os.getenv("GITHUB_MODEL", "openai/gpt-4o-mini"),
    )
else:
    client = OpenAIChatClient(
        api_key=os.environ["OPENAI_API_KEY"], model_id=os.environ.get("OPENAI_MODEL", "gpt-4o-mini")
    )

# Crea los agentes de IA — se pasan directamente como ejecutores al WorkflowBuilder,
# igual que las subclases de Executor en workflow_rag_ingest.py.
writer = Agent(
    client=client,
    name="Escritor",
    instructions=(
        "Eres un escritor de contenido conciso. "
        "Escribe un artículo corto (2-3 párrafos) claro y atractivo sobre el tema del usuario. "
        "Prioriza la precisión y la legibilidad."
    ),
)

reviewer = Agent(
    client=client,
    name="Revisor",
    instructions=(
        "Eres un revisor de contenido reflexivo. "
        "Lee el borrador del escritor y ofrece retroalimentación específica y constructiva. "
        "Comenta sobre la claridad, la precisión y la estructura. Mantén tu revisión concisa."
    ),
)

# Construye el workflow: Escritor → Revisor
# El mismo patrón WorkflowBuilder.add_edge funciona tanto para ejecutores Python
# como para agentes de IA — la estructura del grafo es idéntica.
workflow = WorkflowBuilder(start_executor=writer).add_edge(writer, reviewer).build()


async def main():
    prompt = "Escribe una publicación de LinkedIn sobre tres formas prácticas en que los agentes de IA pueden mejorar los flujos de soporte al cliente."
    logger.info("Prompt: %s", prompt)
    events = await workflow.run(prompt)
    outputs = events.get_outputs()
    for output in outputs:
        logger.info("[%s]\n%s", output.executor_id, output.agent_response.text)

    if async_credential:
        await async_credential.close()


if __name__ == "__main__":
    if "--devui" in sys.argv:
        from agent_framework.devui import serve

        serve(entities=[workflow], port=8092, auto_open=True)
    else:
        asyncio.run(main())
