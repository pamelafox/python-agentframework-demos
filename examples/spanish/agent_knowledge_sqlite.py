"""
RecuperaciÃ³n de conocimiento (RAG) mediante un proveedor de contexto personalizado.

Diagrama:

 Entrada â”€â”€â–¶ Agente â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ LLM â”€â”€â–¶ Respuesta
               â”‚                        â–²
               â”‚  buscar con entrada    â”‚ conocimiento relevante
               â–¼                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
         â”‚   Base de   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ conocimientoâ”‚
         â”‚  (SQLite)   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

El agente recupera conocimiento de una base de datos SQLite FTS5 *antes*
de pedirle al LLM que responda. Como el agente siempre necesita conocimiento
especÃ­fico del dominio para fundamentar sus respuestas, un paso de bÃºsqueda
determinista es mÃ¡s eficiente y confiable que pedirle al LLM que decida
usar una herramienta.

Este ejemplo crea un pequeÃ±o catÃ¡logo de productos y usa un
BaseContextProvider personalizado para inyectar filas relevantes en el contexto del LLM.
"""

import asyncio
import logging
import os
import re
import sqlite3
import sys
from typing import Any

from agent_framework import Agent, AgentSession, BaseContextProvider, Message, SessionContext, SupportsAgentRun
from agent_framework.openai import OpenAIChatClient
from azure.identity.aio import DefaultAzureCredential, get_bearer_token_provider
from dotenv import load_dotenv
from rich import print
from rich.logging import RichHandler

# â”€â”€ Logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
handler = RichHandler(show_path=False, rich_tracebacks=True, show_level=False)
logging.basicConfig(level=logging.WARNING, handlers=[handler], force=True, format="%(message)s")
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# â”€â”€ Cliente OpenAI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv(override=True)
API_HOST = os.getenv("API_HOST", "github")

async_credential = None
if API_HOST == "azure":
    async_credential = DefaultAzureCredential()
    token_provider = get_bearer_token_provider(async_credential, "https://cognitiveservices.azure.com/.default")
    client = OpenAIChatClient(
        base_url=f"{os.environ['AZURE_OPENAI_ENDPOINT']}/openai/v1/",
        api_key=token_provider,
        model_id=os.environ["AZURE_OPENAI_CHAT_DEPLOYMENT"],
    )
elif API_HOST == "github":
    client = OpenAIChatClient(
        base_url="https://models.github.ai/inference",
        api_key=os.environ["GITHUB_TOKEN"],
        model_id=os.getenv("GITHUB_MODEL", "openai/gpt-5-mini"),
    )
else:
    client = OpenAIChatClient(
        api_key=os.environ["OPENAI_API_KEY"], model_id=os.environ.get("OPENAI_MODEL", "gpt-5-mini")
    )


# â”€â”€ Base de conocimiento (SQLite + FTS5) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

PRODUCTS = [
    {
        "name": "Botas de Senderismo TrailBlaze",
        "category": "Calzado",
        "price": 149.99,
        "description": (
            "Botas de senderismo impermeables con suelas Vibram, soporte de tobillo "
            "y forro transpirable Gore-Tex. Ideales para senderos rocosos y condiciones hÃºmedas."
        ),
    },
    {
        "name": "Mochila SummitPack 40L",
        "category": "Mochilas",
        "price": 89.95,
        "description": (
            "Mochila ligera de 40 litros con compartimento para hidrataciÃ³n, cubierta de lluvia "
            "y cinturÃ³n de cadera ergonÃ³mico. Perfecta para excursiones de un dÃ­a o con pernocta."
        ),
    },
    {
        "name": "Chaqueta de PlumÃ³n ArcticShield",
        "category": "Ropa",
        "price": 199.00,
        "description": (
            "Chaqueta de plumÃ³n de ganso 800-fill con clasificaciÃ³n de -28Â°C. "
            "Incluye carcasa resistente al agua, diseÃ±o comprimible y capucha ajustable."
        ),
    },
    {
        "name": "Remo para Kayak RiverRun",
        "category": "Deportes AcuÃ¡ticos",
        "price": 74.50,
        "description": (
            "Remo de fibra de vidrio para kayak con fÃ©rula ajustable y anillos antigoteo. "
            "Ligero (795 g), apto para kayak recreativo y de travesÃ­a."
        ),
    },
    {
        "name": "Bastones de Trekking TerraFirm",
        "category": "Accesorios",
        "price": 59.99,
        "description": (
            "Bastones de trekking plegables de fibra de carbono con empuÃ±aduras de corcho y puntas de tungsteno. "
            "Ajustables de 60 a 137 cm, con amortiguaciÃ³n anti-vibraciÃ³n."
        ),
    },
    {
        "name": "Binoculares ClearView 10x42",
        "category": "Ã“ptica",
        "price": 129.00,
        "description": (
            "Binoculares de prisma de techo con aumento 10x y lentes objetivos de 42 mm. "
            "Cargados con nitrÃ³geno y resistentes al agua. Ideales para observaciÃ³n de aves y fauna."
        ),
    },
    {
        "name": "Linterna Frontal LED NightGlow",
        "category": "IluminaciÃ³n",
        "price": 34.99,
        "description": (
            "Linterna frontal recargable de 350 lÃºmenes con modo de luz roja y haz ajustable. "
            "ClasificaciÃ³n IPX6 de resistencia al agua, hasta 40 horas en modo bajo."
        ),
    },
    {
        "name": "Saco de Dormir CozyNest",
        "category": "Camping",
        "price": 109.00,
        "description": (
            "Saco de dormir tipo momia para tres estaciones, con clasificaciÃ³n de -6Â°C. "
            "Aislamiento sintÃ©tico, saco de compresiÃ³n incluido. Pesa 1.1 kg."
        ),
    },
]


def create_knowledge_db(db_path: str) -> sqlite3.Connection:
    """Crea (o recrea) el catÃ¡logo de productos en SQLite con un Ã­ndice FTS5."""
    conn = sqlite3.connect(db_path)

    # Eliminar tablas existentes para empezar de nuevo
    conn.execute("DROP TABLE IF EXISTS products_fts")
    conn.execute("DROP TABLE IF EXISTS products")

    conn.execute(
        """
        CREATE TABLE products (
            id    INTEGER PRIMARY KEY AUTOINCREMENT,
            name  TEXT NOT NULL,
            category TEXT NOT NULL,
            price REAL NOT NULL,
            description TEXT NOT NULL
        )
        """
    )
    conn.executemany(
        "INSERT INTO products (name, category, price, description) VALUES (?, ?, ?, ?)",
        [(p["name"], p["category"], p["price"], p["description"]) for p in PRODUCTS],
    )

    # Crear Ã­ndice de bÃºsqueda de texto completo sobre nombre, categorÃ­a y descripciÃ³n
    conn.execute(
        """
        CREATE VIRTUAL TABLE products_fts USING fts5(
            name, category, description,
            content='products',
            content_rowid='id'
        )
        """
    )
    conn.execute(
        "INSERT INTO products_fts (rowid, name, category, description) "
        "SELECT id, name, category, description FROM products"
    )
    conn.commit()
    return conn


# â”€â”€ Proveedor de contexto personalizado para recuperaciÃ³n de conocimiento â”€â”€


class SQLiteKnowledgeProvider(BaseContextProvider):
    """Recupera conocimiento relevante de productos desde SQLite FTS5 antes de cada llamada al LLM.

    Sigue el patrÃ³n de "recuperaciÃ³n de conocimiento" donde el agente busca
    de manera determinista en una base de conocimiento *antes* de que el LLM
    se ejecute, en lugar de depender de que el LLM decida llamar a una herramienta
    de bÃºsqueda. Esto asegura que el modelo siempre tenga contexto especÃ­fico
    del dominio para fundamentar su respuesta.
    """

    def __init__(self, db_conn: sqlite3.Connection, max_results: int = 3):
        super().__init__(source_id="sqlite-knowledge")
        self.db_conn = db_conn
        self.max_results = max_results

    def _search(self, query: str) -> list[dict]:
        """Ejecuta una consulta FTS5 y devuelve productos coincidentes."""
        # Extraer palabras, filtrar cortas (len <= 2 elimina "a", "de", "el", etc.)
        words = re.findall(r"[a-zA-ZÃ¡Ã©Ã­Ã³ÃºÃ±ÃÃ‰ÃÃ“ÃšÃ‘]+", query)
        tokens = [w.lower() for w in words if len(w) > 2]
        if not tokens:
            return []
        fts_query = " OR ".join(tokens)

        try:
            cursor = self.db_conn.execute(
                """
                SELECT p.name, p.category, p.price, p.description
                FROM products_fts fts
                JOIN products p ON fts.rowid = p.id
                WHERE products_fts MATCH ?
                ORDER BY rank
                LIMIT ?
                """,
                (fts_query, self.max_results),
            )
            return [
                {"name": row[0], "category": row[1], "price": row[2], "description": row[3]}
                for row in cursor.fetchall()
            ]
        except Exception:
            logger.debug("Consulta FTS fallÃ³ para: %s", fts_query, exc_info=True)
            return []

    def _format_results(self, results: list[dict]) -> str:
        """Formatea los resultados de bÃºsqueda como texto para el contexto del LLM."""
        lines = ["InformaciÃ³n relevante de productos de nuestro catÃ¡logo:\n"]
        for product in results:
            lines.append(
                f"- **{product['name']}** ({product['category']}, ${product['price']:.2f}): "
                f"{product['description']}"
            )
        return "\n".join(lines)

    async def before_run(
        self,
        *,
        agent: SupportsAgentRun,
        session: AgentSession,
        context: SessionContext,
        state: dict[str, Any],
    ) -> None:
        """Busca en la base de conocimiento con el Ãºltimo mensaje del usuario e inyecta resultados."""
        user_text = next((msg.text for msg in reversed(context.input_messages) if msg.role == "user" and msg.text), None)
        if not user_text:
            return

        results = self._search(user_text)
        if not results:
            logger.info("[ğŸ“š Conocimiento] No se encontraron productos para: %s", user_text)
            return

        logger.info("[ğŸ“š Conocimiento] Se encontraron %d producto(s) para: %s", len(results), user_text)

        context.extend_messages(
            self.source_id,
            [Message(role="user", text=self._format_results(results))],
        )


# â”€â”€ ConfiguraciÃ³n del agente â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

DB_PATH = ":memory:"  # BD en memoria â€” no necesita limpieza de archivos

# Crear y poblar la base de conocimiento
db_conn = create_knowledge_db(DB_PATH)
knowledge_provider = SQLiteKnowledgeProvider(db_conn=db_conn)

agent = Agent(
    client=client,
    instructions=(
        "Eres un asistente de compras de equipo para actividades al aire libre de la tienda 'TrailBuddy'. "
        "Responde las preguntas del cliente usando SOLO la informaciÃ³n de productos proporcionada en el contexto. "
        "Si no se encuentran productos relevantes en el contexto, di que no tienes informaciÃ³n sobre ese artÃ­culo. "
        "Incluye precios al recomendar productos."
    ),
    context_providers=[knowledge_provider],
)


async def main() -> None:
    """Demuestra el patrÃ³n de recuperaciÃ³n de conocimiento (RAG) con varias consultas."""
    # Consulta 1: DeberÃ­a encontrar botas de senderismo y bastones de trekking
    print("\n[bold]=== Demo de RecuperaciÃ³n de Conocimiento (RAG) ===[/bold]")
    print("[dim]El agente busca en una base de conocimiento SQLite FTS5 antes de cada llamada al LLM.[/dim]\n")

    print("[blue]Usuario:[/blue] Estoy planeando una excursiÃ³n. Â¿QuÃ© botas y bastones me recomiendan?")
    response = await agent.run("Estoy planeando una excursiÃ³n. Â¿QuÃ© botas y bastones me recomiendan?")
    print(f"[green]Agente:[/green] {response.text}\n")

    # Consulta 2: DeberÃ­a encontrar la chaqueta de plumÃ³n
    print("[blue]Usuario:[/blue] Necesito algo abrigado para acampar en invierno, Â¿tienen alguna chaqueta?")
    response = await agent.run("Necesito algo abrigado para acampar en invierno, Â¿tienen alguna chaqueta?")
    print(f"[green]Agente:[/green] {response.text}\n")

    # Consulta 3: DeberÃ­a encontrar el remo de kayak
    print("[blue]Usuario:[/blue] Â¿Venden algo para kayak?")
    response = await agent.run("Â¿Venden algo para kayak?")
    print(f"[green]Agente:[/green] {response.text}\n")

    # Consulta 4: Sin coincidencia â€” demuestra manejo de "sin conocimiento"
    print("[blue]Usuario:[/blue] Â¿Tienen tablas de surf?")
    response = await agent.run("Â¿Tienen tablas de surf?")
    print(f"[green]Agente:[/green] {response.text}\n")

    db_conn.close()

    if async_credential:
        await async_credential.close()


if __name__ == "__main__":
    if "--devui" in sys.argv:
        from agent_framework.devui import serve

        serve(entities=[agent], auto_open=True)
    else:
        asyncio.run(main())
